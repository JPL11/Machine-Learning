{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import os\n",
        "import datetime\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import multiprocessing\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# For model conversion\n",
        "from tensorflow.python.framework import graph_util\n",
        "from tensorflow.python.framework import graph_io\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "DIcV2UPi2oxE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_events(file, max_events=None):\n",
        "    \"\"\"Load DVS events from a text file or uploaded file object with optimized batch parsing.\"\"\"\n",
        "    import io\n",
        "\n",
        "    if isinstance(file, str):\n",
        "        # File path from disk\n",
        "        with open(file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "    elif isinstance(file, io.BytesIO):\n",
        "        # Uploaded file from Colab\n",
        "        lines = file.read().decode('utf-8').splitlines()\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file type\")\n",
        "\n",
        "    # Skip header\n",
        "    start_idx = 0\n",
        "    for i, line in enumerate(lines):\n",
        "        if line.startswith('#'):\n",
        "            start_idx = i + 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # Process lines in batches\n",
        "    batch_size = 10000\n",
        "    total_events = len(lines) - start_idx\n",
        "    if max_events is not None:\n",
        "        total_events = min(total_events, max_events)\n",
        "\n",
        "    events = []\n",
        "    for i in range(0, total_events, batch_size):\n",
        "        end_idx = min(i + batch_size, total_events)\n",
        "        batch_lines = lines[start_idx + i : start_idx + end_idx]\n",
        "\n",
        "        for line in batch_lines:\n",
        "            try:\n",
        "                t, x, y, p = line.strip().split()\n",
        "                events.append((float(t), int(x), int(y), int(p)))\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "    print(f\"✅ Loaded {len(events)} events\")\n",
        "    return np.array(events, dtype=[('t', np.float32), ('x', np.int16), ('y', np.int16), ('p', np.int8)])\n"
      ],
      "metadata": {
        "id": "C_sQj1Q3-NmI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_events_from_csv(file, max_events=None, cols=None, has_header=True):\n",
        "    \"\"\"\n",
        "    Load DVS events from a CSV file with flexible column mapping.\n",
        "\n",
        "    Args:\n",
        "        file: Path to CSV file (can be Google Drive path)\n",
        "        max_events: Maximum number of events to load (None for all)\n",
        "        cols: List of column indices [t_col, x_col, y_col, p_col] or None to use default mappings\n",
        "        has_header: Whether the CSV has a header row\n",
        "\n",
        "    Returns:\n",
        "        Structured numpy array of events (t, x, y, p)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Ensure file exists\n",
        "        if not os.path.exists(file):\n",
        "            raise FileNotFoundError(f\"File not found: {file}\")\n",
        "\n",
        "        # Read CSV file\n",
        "        if has_header:\n",
        "            df = pd.read_csv(file)\n",
        "        else:\n",
        "            df = pd.read_csv(file, header=None)\n",
        "\n",
        "        # Display first few rows to understand the data\n",
        "        print(f\"Preview of data from {file}:\")\n",
        "        print(df.head())\n",
        "\n",
        "        # If columns not specified, try to determine them\n",
        "        if cols is None:\n",
        "            # If columns have standard names\n",
        "            if all(col in df.columns for col in ['t', 'x', 'y', 'p']):\n",
        "                t_col, x_col, y_col, p_col = 't', 'x', 'y', 'p'\n",
        "            # If columns are named with letters (A, B, C...)\n",
        "            elif all(col in df.columns for col in ['A', 'B', 'C', 'D']):\n",
        "                t_col, x_col, y_col, p_col = 'A', 'B', 'C', 'D'\n",
        "            # Otherwise use first four columns\n",
        "            else:\n",
        "                t_col = df.columns[0]\n",
        "                x_col = df.columns[1]\n",
        "                y_col = df.columns[2]\n",
        "                p_col = df.columns[3]\n",
        "                print(f\"Using columns {t_col}, {x_col}, {y_col}, {p_col} for t, x, y, p\")\n",
        "        else:\n",
        "            # Use provided column indices\n",
        "            t_col, x_col, y_col, p_col = [df.columns[i] for i in cols]\n",
        "\n",
        "        # Limit events if needed\n",
        "        if max_events is not None:\n",
        "            df = df.head(max_events)\n",
        "\n",
        "        # Check range of values to determine appropriate data types\n",
        "        t_min, t_max = df[t_col].min(), df[t_col].max()\n",
        "        x_min, x_max = df[x_col].min(), df[x_col].max()\n",
        "        y_min, y_max = df[y_col].min(), df[y_col].max()\n",
        "        p_min, p_max = df[p_col].min(), df[p_col].max()\n",
        "\n",
        "        print(f\"Value ranges:\")\n",
        "        print(f\"  t: {t_min} to {t_max}\")\n",
        "        print(f\"  x: {x_min} to {x_max}\")\n",
        "        print(f\"  y: {y_min} to {y_max}\")\n",
        "        print(f\"  p: {p_min} to {p_max}\")\n",
        "\n",
        "        # Choose appropriate data types based on values\n",
        "        t_type = np.float64  # Use float64 for timestamps\n",
        "        x_type = np.int32 if x_max > 32767 or x_min < -32768 else np.int16\n",
        "        y_type = np.int32 if y_max > 32767 or y_min < -32768 else np.int16\n",
        "        p_type = np.int32 if p_max > 127 or p_min < -128 else np.int8\n",
        "\n",
        "        # Extract events with appropriate types\n",
        "        events = np.array(list(zip(\n",
        "            df[t_col].astype(float),\n",
        "            df[x_col].astype(int),\n",
        "            df[y_col].astype(int),\n",
        "            df[p_col].astype(int)\n",
        "        )), dtype=[('t', t_type), ('x', x_type), ('y', y_type), ('p', p_type)])\n",
        "\n",
        "        print(f\"✅ Loaded {len(events)} events from CSV with data types: t={t_type}, x={x_type}, y={y_type}, p={p_type}\")\n",
        "        return events\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading CSV: {str(e)}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "OzMhO4S9z1_-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_events_to_csv(events, output_file, include_header=True):\n",
        "    \"\"\"\n",
        "    Save DVS events to a CSV file with standard column names.\n",
        "\n",
        "    Args:\n",
        "        events: Structured numpy array of events (t, x, y, p)\n",
        "        output_file: Path to save CSV file (can be Google Drive path)\n",
        "        include_header: Whether to include a header row\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create directory if it doesn't exist\n",
        "        output_dir = os.path.dirname(output_file)\n",
        "        if output_dir and not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Convert structured array to DataFrame with standard column names\n",
        "        df = pd.DataFrame({\n",
        "            't': events['t'],\n",
        "            'x': events['x'],\n",
        "            'y': events['y'],\n",
        "            'p': events['p']\n",
        "        })\n",
        "\n",
        "        # Save to CSV\n",
        "        df.to_csv(output_file, index=False, header=include_header)\n",
        "        print(f\"✅ Saved {len(events)} events to {output_file}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error saving CSV: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def convert_txt_to_csv(txt_file, csv_file, has_header=False):\n",
        "    \"\"\"\n",
        "    Convert space-delimited text event file to CSV format with standard column names.\n",
        "\n",
        "    Args:\n",
        "        txt_file: Path to input text file\n",
        "        csv_file: Path to output CSV file\n",
        "        has_header: Whether text file has a header row to preserve\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load events from text file\n",
        "        events = load_events(txt_file)\n",
        "\n",
        "        # Save to CSV with standard column names\n",
        "        save_events_to_csv(events, csv_file, include_header=True)\n",
        "        print(f\"✅ Converted {txt_file} to {csv_file}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error converting file: {str(e)}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "U9G4p6o8bdyw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load files from Google Drive\n",
        "import os\n",
        "\n",
        "# Ask for file format\n",
        "file_format = input(\"Enter file format (txt or csv): \").lower()\n",
        "is_csv = file_format == \"csv\"\n",
        "\n",
        "# Get file paths from Google Drive\n",
        "print(\"Enter the path to your files in Google Drive:\")\n",
        "print(\"Example: /content/drive/MyDrive/DVSTraining\")\n",
        "base_path = input(\"Base path: \")\n",
        "\n",
        "# Get filenames\n",
        "print(\"Enter the filenames (relative to the base path):\")\n",
        "noisy_filename = input(\"Noisy events filename: \")\n",
        "clean_filename = input(\"Clean events filename: \")\n",
        "\n",
        "# Construct full paths\n",
        "noisy_file = os.path.join(base_path, noisy_filename)\n",
        "clean_file = os.path.join(base_path, clean_filename)\n",
        "\n",
        "# Verify files exist\n",
        "if not os.path.exists(noisy_file):\n",
        "    raise FileNotFoundError(f\"File not found: {noisy_file}\")\n",
        "if not os.path.exists(clean_file):\n",
        "    raise FileNotFoundError(f\"File not found: {clean_file}\")\n",
        "\n",
        "print(f\"Loading files:\\n  - {noisy_file}\\n  - {clean_file}\")\n",
        "\n",
        "# Load event data using the appropriate function\n",
        "if is_csv:\n",
        "    # For CSV files, we need to determine which columns to use (first 4 columns)\n",
        "    noisy_events = load_events_from_csv(noisy_file, cols=[0, 1, 2, 3])\n",
        "    clean_events = load_events_from_csv(clean_file, cols=[0, 1, 2, 3])\n",
        "else:\n",
        "    noisy_events = load_events(noisy_file)\n",
        "    clean_events = load_events(clean_file)\n",
        "\n",
        "print(f\"Loaded {len(noisy_events)} noisy events and {len(clean_events)} clean events\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt_-FFAUFw_a",
        "outputId": "0eaa35c3-dc72-43b6-b7b3-b3fa51dacb6c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter file format (txt or csv): csv\n",
            "Enter the path to your files in Google Drive:\n",
            "Example: /content/drive/MyDrive/DVSTraining\n",
            "Base path: /content/drive/MyDrive/DVSTraining\n",
            "Enter the filenames (relative to the base path):\n",
            "Noisy events filename: mixedhotellightTI25.csv\n",
            "Clean events filename: amixedhotellightTI25.csv\n",
            "Loading files:\n",
            "  - /content/drive/MyDrive/DVSTraining/mixedhotellightTI25.csv\n",
            "  - /content/drive/MyDrive/DVSTraining/amixedhotellightTI25.csv\n",
            "Preview of data from /content/drive/MyDrive/DVSTraining/mixedhotellightTI25.csv:\n",
            "   -1   60  131  1610903445  1  2090596  5096365  2089490  2120375  2079095  \\\n",
            "0   1  181  158  1610903470  1  2120900  5579979  3438179  3001284  5335559   \n",
            "1   1  172  159  1610903475  1  2114237  5246538  5104601  3884158        0   \n",
            "2  -1  189  154  1610903489  1  2081398  5158468        0  2138209  5492236   \n",
            "3   1  165  159  1610903505  1        0  4325362        0  3118796  5078815   \n",
            "4   1  185  132  1610903509  1        0  2874090  4775733  2123682  5099596   \n",
            "\n",
            "   ...  0.678  0.679  0.680  0.681  0.682  0.683  0.684  0.685  0.686  \\\n",
            "0  ...      0      0      0      0      0      0      0      0      0   \n",
            "1  ...      0      0      0      0      0      0      0      0      0   \n",
            "2  ...      0      0      0      0      0      0      0      0      0   \n",
            "3  ...      0      0      0      0      0      0      0      0      0   \n",
            "4  ...      0      0      0      0      0      0      0      0      0   \n",
            "\n",
            "   1610903445.1  \n",
            "0    1610903445  \n",
            "1    1610903445  \n",
            "2    1610903445  \n",
            "3    1610903445  \n",
            "4    1610903445  \n",
            "\n",
            "[5 rows x 1256 columns]\n",
            "Value ranges:\n",
            "  t: -1 to 1\n",
            "  x: 0 to 345\n",
            "  y: 0 to 259\n",
            "  p: 1607383422 to 1611214820\n",
            "✅ Loaded 79673 events from CSV with data types: t=<class 'numpy.float64'>, x=<class 'numpy.int16'>, y=<class 'numpy.int16'>, p=<class 'numpy.int32'>\n",
            "Preview of data from /content/drive/MyDrive/DVSTraining/amixedhotellightTI25.csv:\n",
            "   265  226  1608383420  0      0.1  2795048  4632868  4529021  4522710  \\\n",
            "0  283  166  1608383425  1  4618167  4615269  4590981  4578587  4563194   \n",
            "1  108  168  1608383425  1  4657548        0  4657799  4620166  4600876   \n",
            "2  263  153  1608383427  1  4648053  4640656  4652750  4638158  4653350   \n",
            "3  114  154  1608383481  1  4590679  4558433  4550100  2868324        0   \n",
            "4  101  134  1608383485  1  4617268  4590781  4566792  2871912  4629264   \n",
            "\n",
            "   4639112  ...    0.244  4541095    0.245  4538226  4650382    0.246  \\\n",
            "0  4647353  ...  2807543  2810416  4654950  2903543  4627263  4645844   \n",
            "1  4647307  ...  4634160  4598177  4628892  4576188        0  4624064   \n",
            "2  4628290  ...  4592280  4577587  4545203  4526912        0  4566681   \n",
            "3        0  ...        0  4654817  2894701  2915390  4585883  4630162   \n",
            "4  4576499  ...  4579086  4546002  4516716  4649531  2905395  2873311   \n",
            "\n",
            "   4533849  4645822    0.247  1608383425  \n",
            "0  4637223  4583654  2904596  1608383425  \n",
            "1  4584384  4560695  4560548  1608383425  \n",
            "2  4580785  4649788  4520915  1608383425  \n",
            "3  4626905  4576987  4535670  1608383425  \n",
            "4  4651639        0  4650796  1608383425  \n",
            "\n",
            "[5 rows x 630 columns]\n",
            "Value ranges:\n",
            "  t: 0 to 345\n",
            "  x: 0 to 259\n",
            "  y: 1608383425 to 1608883405\n",
            "  p: 0 to 1\n",
            "✅ Loaded 35624 events from CSV with data types: t=<class 'numpy.float64'>, x=<class 'numpy.int16'>, y=<class 'numpy.int32'>, p=<class 'numpy.int8'>\n",
            "Loaded 79673 noisy events and 35624 clean events\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define this function at the module level, outside any other function\n",
        "def process_chunk(chunk, height, width):\n",
        "    local_ti = np.zeros((height, width), dtype=np.float32)\n",
        "    local_pol = np.zeros((height, width), dtype=np.float32)\n",
        "\n",
        "    for t, x, y, p in chunk:\n",
        "        if 0 <= x < width and 0 <= y < height:\n",
        "            local_ti[y, x] = t\n",
        "            local_pol[y, x] = 1 if p == 1 else -1\n",
        "\n",
        "    return local_ti, local_pol\n",
        "\n",
        "# Then modify the function to use the global function\n",
        "def build_timestamp_image_parallel(events, width=346, height=260, num_workers=None):\n",
        "    \"\"\"Build a timestamp image with parallel processing for large datasets.\"\"\"\n",
        "    if num_workers is None:\n",
        "        num_workers = max(1, multiprocessing.cpu_count() - 1)\n",
        "\n",
        "    # Initialize timestamp image with zeros\n",
        "    ti = np.zeros((height, width), dtype=np.float32)\n",
        "    polarity_img = np.zeros((height, width), dtype=np.float32)\n",
        "\n",
        "    # Create chunks of events for parallel processing\n",
        "    chunk_size = max(1000, len(events) // (num_workers * 10))\n",
        "    chunks = [events[i:i+chunk_size] for i in range(0, len(events), chunk_size)]\n",
        "\n",
        "    # Process chunks in parallel\n",
        "    if num_workers > 1 and len(chunks) > 1:\n",
        "        # Pass height and width to the function using partial\n",
        "        from functools import partial\n",
        "        process_func = partial(process_chunk, height=height, width=width)\n",
        "\n",
        "        with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
        "            results = list(executor.map(process_func, chunks))\n",
        "\n",
        "        # Merge results - take the most recent timestamp for each pixel\n",
        "        for local_ti, local_pol in results:\n",
        "            # Update main TI with newer timestamps\n",
        "            mask = (local_ti > 0) & ((ti == 0) | (local_ti > ti))\n",
        "            ti[mask] = local_ti[mask]\n",
        "            polarity_img[mask] = local_pol[mask]\n",
        "    else:\n",
        "        # For small datasets, just process sequentially\n",
        "        for t, x, y, p in events:\n",
        "            if 0 <= x < width and 0 <= y < height:\n",
        "                ti[y, x] = t\n",
        "                polarity_img[y, x] = 1 if p == 1 else -1\n",
        "\n",
        "    return ti, polarity_img"
      ],
      "metadata": {
        "id": "792D-Cvd-mOk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def match_events(noisy_events, clean_events, tau=0.1, spatial_threshold=1):\n",
        "    \"\"\"\n",
        "    Match noisy events to clean events using spatiotemporal correlation as described in the paper.\n",
        "\n",
        "    Args:\n",
        "        noisy_events: Array of noisy events (t, x, y, p)\n",
        "        clean_events: Array of clean events (t, x, y, p)\n",
        "        tau: Time correlation window (in seconds)\n",
        "        spatial_threshold: Maximum spatial distance to consider a match\n",
        "\n",
        "    Returns:\n",
        "        Numpy array of labels (1 for signal, 0 for noise)\n",
        "    \"\"\"\n",
        "    # Build a spatial index for clean events\n",
        "    clean_event_dict = defaultdict(list)\n",
        "    for i, (t, x, y, p) in enumerate(clean_events):\n",
        "        # Store events by their spatial location\n",
        "        clean_event_dict[(x, y)].append((t, p, i))\n",
        "\n",
        "    # Create labels array\n",
        "    labels = np.zeros(len(noisy_events), dtype=np.int8)\n",
        "\n",
        "    # Match each noisy event to clean events\n",
        "    for i, (t_noisy, x_noisy, y_noisy, p_noisy) in enumerate(noisy_events):\n",
        "        # Check nearby pixels within spatial threshold\n",
        "        is_signal = False\n",
        "\n",
        "        # Efficient spatial search using a window around the event\n",
        "        for dx in range(-spatial_threshold, spatial_threshold + 1):\n",
        "            for dy in range(-spatial_threshold, spatial_threshold + 1):\n",
        "                x_clean = x_noisy + dx\n",
        "                y_clean = y_noisy + dy\n",
        "\n",
        "                # Check if there are any clean events at this location\n",
        "                for t_clean, p_clean, _ in clean_event_dict.get((x_clean, y_clean), []):\n",
        "                    # Check temporal correlation\n",
        "                    if abs(t_noisy - t_clean) < tau:\n",
        "                        # Check polarity match\n",
        "                        if p_noisy == p_clean:\n",
        "                            is_signal = True\n",
        "                            break\n",
        "\n",
        "                if is_signal:\n",
        "                    break\n",
        "\n",
        "            if is_signal:\n",
        "                break\n",
        "\n",
        "        # Label the event\n",
        "        labels[i] = 1 if is_signal else 0\n",
        "\n",
        "    return labels"
      ],
      "metadata": {
        "id": "qb9Bm3RNAGHA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_patches_batch(ti, polarity_img, events, patch_size=7, tau=0.1, batch_size=128):\n",
        "    \"\"\"\n",
        "    Extract patches from timestamp image with enhanced polarity encoding as in the paper model.\n",
        "\n",
        "    Args:\n",
        "        ti: Timestamp image\n",
        "        polarity_img: Polarity image\n",
        "        events: Array of events (t, x, y, p)\n",
        "        patch_size: Size of the patch (7x7 as in the paper)\n",
        "        tau: Time correlation window\n",
        "        batch_size: Number of events to process at once (128 as in paper)\n",
        "\n",
        "    Returns:\n",
        "        Array of features for each event with timestamp and polarity channels\n",
        "    \"\"\"\n",
        "    half_size = patch_size // 2\n",
        "    height, width = ti.shape\n",
        "    features_list = []\n",
        "\n",
        "    # Process events in batches\n",
        "    for i in range(0, len(events), batch_size):\n",
        "        batch_events = events[i:i+batch_size]\n",
        "        batch_features = []\n",
        "\n",
        "        for t, x, y, p in batch_events:\n",
        "            # Extract timestamp and polarity patches\n",
        "            if x < half_size or x >= width - half_size or y < half_size or y >= height - half_size:\n",
        "                # Handle events near the border\n",
        "                # Create empty patches\n",
        "                time_patch = np.zeros((patch_size, patch_size), dtype=np.float32)\n",
        "                pol_patch = np.zeros((patch_size, patch_size), dtype=np.float32)\n",
        "\n",
        "                # Calculate patch boundaries and offsets\n",
        "                x_min = max(0, x - half_size)\n",
        "                x_max = min(width, x + half_size + 1)\n",
        "                y_min = max(0, y - half_size)\n",
        "                y_max = min(height, y + half_size + 1)\n",
        "\n",
        "                x_offset = half_size - (x - x_min)\n",
        "                y_offset = half_size - (y - y_min)\n",
        "\n",
        "                # Copy data into patches\n",
        "                patch_width = x_max - x_min\n",
        "                patch_height = y_max - y_min\n",
        "\n",
        "                time_patch[y_offset:y_offset+patch_height, x_offset:x_offset+patch_width] = ti[y_min:y_max, x_min:x_max]\n",
        "                pol_patch[y_offset:y_offset+patch_height, x_offset:x_offset+patch_width] = polarity_img[y_min:y_max, x_min:x_max]\n",
        "            else:\n",
        "                # Extract patches directly for events not near the border\n",
        "                time_patch = ti[y-half_size:y+half_size+1, x-half_size:x+half_size+1].copy()\n",
        "                pol_patch = polarity_img[y-half_size:y+half_size+1, x-half_size:x+half_size+1].copy()\n",
        "\n",
        "            # Normalize the timestamp patch according to equation (4) in the paper\n",
        "            time_diff = t - time_patch\n",
        "            time_patch_norm = np.clip((tau - np.abs(time_diff)) / tau, 0, 1)\n",
        "\n",
        "            # Create separate polarity channels (this is the key change for \"polarity=2\")\n",
        "            # First channel: original polarity values\n",
        "            pol_channel1 = pol_patch.copy()\n",
        "\n",
        "            # Second channel: binary polarity for this event\n",
        "            pol_channel2 = np.zeros_like(pol_patch)\n",
        "            center = patch_size // 2\n",
        "            pol_channel2[center, center] = 1 if p == 1 else -1\n",
        "\n",
        "            # Set polarity to 0 where timestamp is too old\n",
        "            pol_channel1[time_patch_norm == 0] = 0\n",
        "            pol_channel2[time_patch_norm == 0] = 0\n",
        "\n",
        "            # Flatten and combine all channels (creates 147 features)\n",
        "            features = np.hstack((time_patch_norm.flatten(), pol_channel1.flatten(), pol_channel2.flatten()))\n",
        "            batch_features.append(features)\n",
        "\n",
        "        features_list.extend(batch_features)\n",
        "\n",
        "    return np.array(features_list)"
      ],
      "metadata": {
        "id": "fBcdtNBsE-ti"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_mlpf_model(input_size=147, hidden_units=20):\n",
        "    \"\"\"\n",
        "    Build the MLPF model with parameters from the paper.\n",
        "\n",
        "    Args:\n",
        "        input_size: Size of input features (7x7x3 = 147)\n",
        "        hidden_units: Number of hidden units (20 as in paper)\n",
        "\n",
        "    Returns:\n",
        "        Compiled MLPF model\n",
        "    \"\"\"\n",
        "    inputs = Input(shape=(input_size,), name='input')\n",
        "    x = Dense(hidden_units, activation='softmax', name='fc1')(inputs)  # Using softmax as in their code\n",
        "    x = Dropout(0.3)(x)  # Increased from 0.2 to 0.3 as in their implementation\n",
        "    x = Dense(1, activation='sigmoid', name='output')(x)\n",
        "    model = Model(inputs=inputs, outputs=x, name='MLPF')\n",
        "    return model\n",
        "\n",
        "def train_mlpf(X_train, y_train, X_val, y_val, hidden_units=20, batch_size=128, epochs=5, learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    Train MLPF model with parameters matching the paper.\n",
        "    \"\"\"\n",
        "    input_size = X_train.shape[1]\n",
        "    model = build_mlpf_model(input_size, hidden_units)\n",
        "\n",
        "    # Compile the model with MSE loss and AUC metric\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='mean_squared_error',  # Use MSE as in the paper\n",
        "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]  # Add AUC metric\n",
        "    )\n",
        "    model.summary()\n",
        "\n",
        "    # Callbacks - change to monitor val_auc\n",
        "    checkpoint_path = \"mlpf_model_best.h5\"\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        checkpoint_path,\n",
        "        monitor='val_auc',  # Monitor AUC instead of accuracy\n",
        "        verbose=1,\n",
        "        save_best_only=True,\n",
        "        mode='max'\n",
        "    )\n",
        "\n",
        "    # Calculate class weights to handle imbalance\n",
        "    from sklearn.utils.class_weight import compute_class_weight\n",
        "    import numpy as np\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,  # Increased to 30 as in their training graph\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=[checkpoint],\n",
        "        class_weight=class_weight_dict,  # Add class weights\n",
        "        verbose=1\n",
        "    )\n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "xW_zkgJyL29T"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_h5_to_pb(h5_model_path, output_dir=\"pb_model\"):\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    import os\n",
        "\n",
        "    # Create output directory\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Load model\n",
        "    model = keras.models.load_model(h5_model_path)\n",
        "\n",
        "    # Convert to SavedModel format\n",
        "    saved_model_path = os.path.join(output_dir, \"saved_model\")\n",
        "    tf.saved_model.save(model, saved_model_path)\n",
        "\n",
        "    # Convert to TFLite (optional)\n",
        "    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    # Save the converted model\n",
        "    pb_file_path = os.path.join(output_dir, os.path.basename(h5_model_path).replace(\".h5\", \".pb\"))\n",
        "    with open(pb_file_path, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "    print(f\"Model saved as {pb_file_path}\")\n",
        "    return pb_file_path"
      ],
      "metadata": {
        "id": "XYIg86ItMBLU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_manual_roc_auc(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate ROC AUC exactly as in the paper implementation.\n",
        "    \"\"\"\n",
        "    from sklearn.metrics import confusion_matrix, auc\n",
        "    import numpy as np\n",
        "\n",
        "    tps = []\n",
        "    fps = []\n",
        "\n",
        "    # Use their specific threshold range and steps\n",
        "    for threshold in range(10, 100, 20):  # 10%, 30%, 50%, 70%, 90%\n",
        "        y_pred_binary = (y_pred > threshold/100).astype(int)\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred_binary).ravel()\n",
        "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "        tps.append(tpr)\n",
        "        fps.append(fpr)\n",
        "\n",
        "    # Additional thresholds at 75% and 99%\n",
        "    for threshold in [75, 99]:\n",
        "        y_pred_binary = (y_pred > threshold/100).astype(int)\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred_binary).ravel()\n",
        "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "        tps.append(tpr)\n",
        "        fps.append(fpr)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    tprarr = np.array(tps)\n",
        "    fprarr = np.array(fps)\n",
        "\n",
        "    # Sort by FPR\n",
        "    sorted_indices = np.argsort(fprarr)\n",
        "    sorted_fprarr = fprarr[sorted_indices]\n",
        "    sorted_tprarr = tprarr[sorted_indices]\n",
        "\n",
        "    # Add boundary points after sorting\n",
        "    sorted_fprarr = np.concatenate(([0], sorted_fprarr, [1]))\n",
        "    sorted_tprarr = np.concatenate(([0], sorted_tprarr, [1]))\n",
        "\n",
        "    # Calculate AUC\n",
        "    auc_value = auc(sorted_fprarr, sorted_tprarr)\n",
        "    return auc_value, sorted_fprarr, sorted_tprarr"
      ],
      "metadata": {
        "id": "UKk5q3-Sgokp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_denoising_pipeline(noisy_file, clean_file, patch_size=7, tau=0.1, hidden_units=20,\n",
        "                          batch_size=128, epochs=5, convert_to_pb=True,\n",
        "                          input_is_csv=False, csv_cols=[0, 1, 2, 3], save_denoised=False, output_csv=None):\n",
        "    \"\"\"\n",
        "    Complete DVS denoising pipeline with optimizations.\n",
        "\n",
        "    Args:\n",
        "        noisy_file: Path to noisy events file\n",
        "        clean_file: Path to clean events file\n",
        "        patch_size: Size of patch for feature extraction\n",
        "        tau: Time correlation window\n",
        "        hidden_units: Number of hidden units in model\n",
        "        batch_size: Batch size for training\n",
        "        epochs: Number of training epochs\n",
        "        convert_to_pb: Whether to convert model to .pb format\n",
        "        input_is_csv: Whether input files are CSV format\n",
        "        save_denoised: Whether to save denoised events\n",
        "        output_csv: Path to save denoised events (if save_denoised=True)\n",
        "    \"\"\"\n",
        "    # Step 1: Load data\n",
        "    print(\"Loading data...\")\n",
        "    start_time = time.time()\n",
        "    if input_is_csv:\n",
        "        noisy_events = load_events_from_csv(noisy_file)\n",
        "        clean_events = load_events_from_csv(clean_file)\n",
        "    else:\n",
        "        noisy_events = load_events(noisy_file)\n",
        "        clean_events = load_events(clean_file)\n",
        "    print(f\"Data loading completed in {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "    # Step 2: Build timestamp images\n",
        "    print(\"Building timestamp images...\")\n",
        "    start_time = time.time()\n",
        "    width, height = 346, 260  # DAVIS346 resolution\n",
        "    ti, polarity_img = build_timestamp_image_parallel(noisy_events, width, height)\n",
        "    print(f\"Timestamp image building completed in {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "    # Step 3: Match events for training\n",
        "    print(\"Matching events for training labels...\")\n",
        "    start_time = time.time()\n",
        "    labels = match_events(noisy_events, clean_events, tau)\n",
        "    print(f\"Event matching completed in {time.time() - start_time:.2f} seconds\")\n",
        "    print(f\"Found {np.sum(labels)} signal events and {len(labels) - np.sum(labels)} noise events\")\n",
        "\n",
        "    # Step 4: Extract patches\n",
        "    print(\"Extracting patches...\")\n",
        "    start_time = time.time()\n",
        "    features = extract_patches_batch(ti, polarity_img, noisy_events, patch_size, tau, batch_size)\n",
        "    print(f\"Patch extraction completed in {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "    # Step 5: Split data\n",
        "    X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "    print(f\"Training set: {X_train.shape[0]} samples, Validation set: {X_val.shape[0]} samples\")\n",
        "\n",
        "    # Step 6: Train model\n",
        "    print(\"Training model...\")\n",
        "    model, history = train_mlpf(X_train, y_train, X_val, y_val, hidden_units, batch_size, epochs)\n",
        "\n",
        "    # Step 7: Evaluate model\n",
        "    print(\"Evaluating model...\")\n",
        "    evaluation_results = model.evaluate(X_val, y_val, verbose=1)\n",
        "\n",
        "    # Handle varying number of metrics\n",
        "    val_loss = evaluation_results[0]  # First value is always the loss\n",
        "    val_metrics = evaluation_results[1:]  # Remaining values are metrics\n",
        "\n",
        "    print(f\"Validation loss: {val_loss:.4f}\")\n",
        "    # Print any additional metrics\n",
        "    metric_names = model.metrics_names[1:]  # Skip 'loss'\n",
        "    for name, value in zip(metric_names, val_metrics):\n",
        "        print(f\"Validation {name}: {value:.4f}\")\n",
        "\n",
        "    # Step 8: Plot ROC curve\n",
        "    y_pred = model.predict(X_val)\n",
        "    # Calculate standard ROC and AUC for comparison\n",
        "    fpr_standard, tpr_standard, thresholds = roc_curve(y_val, y_pred)\n",
        "    roc_auc_standard = auc(fpr_standard, tpr_standard)\n",
        "\n",
        "    # Calculate manual ROC and AUC using the paper's methodology\n",
        "    roc_auc, fps, tps = calculate_manual_roc_auc(y_val, y_pred)\n",
        "\n",
        "    print(f\"Standard AUC: {roc_auc_standard:.4f}\")\n",
        "    print(f\"Manual calculation AUC: {roc_auc:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    # Plot standard ROC\n",
        "    plt.plot(fpr_standard, tpr_standard, color='blue', lw=2, label=f'Standard ROC (area = {roc_auc_standard:.2f})')\n",
        "    # Plot manual ROC\n",
        "    plt.plot(fps, tps, color='darkorange', lw=2, label=f'Manual ROC (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.savefig('roc_curve.pdf')\n",
        "    plt.show()\n",
        "\n",
        "    # Step 9: Save model and convert to pb if requested\n",
        "    model_path = \"mlpf_model_final.h5\"\n",
        "    model.save(model_path)\n",
        "    print(f\"Model saved as {model_path}\")\n",
        "\n",
        "    if convert_to_pb:\n",
        "        pb_path = convert_h5_to_pb(model_path)\n",
        "        print(f\"Model converted to PB format: {pb_path}\")\n",
        "\n",
        "    # Step 10: Save denoised events if requested\n",
        "    if save_denoised and output_csv:\n",
        "        print(f\"Saving denoised events to {output_csv}...\")\n",
        "        denoised_events = denoise_events(noisy_events, model, ti, polarity_img,\n",
        "                                        patch_size, tau, threshold=0.5, batch_size=batch_size)\n",
        "        save_events_to_csv(denoised_events, output_csv)\n",
        "\n",
        "        # Calculate noise reduction statistics\n",
        "        original_count = len(noisy_events)\n",
        "        denoised_count = len(denoised_events)\n",
        "        removed_pct = 100 * (1 - denoised_count/original_count)\n",
        "        print(f\"Original events: {original_count}\")\n",
        "        print(f\"Denoised events: {denoised_count}\")\n",
        "        print(f\"Removed noise: {removed_pct:.2f}%\")\n",
        "\n",
        "    return model, history, roc_auc"
      ],
      "metadata": {
        "id": "IXwOCwAOMDaq"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def denoise_events(events, model, ti, polarity_img, patch_size=7, tau=0.1, threshold=0.5, batch_size=128):\n",
        "    \"\"\"\n",
        "    Denoise events using the trained MLPF model with updated polarity handling.\n",
        "    \"\"\"\n",
        "    height, width = ti.shape\n",
        "    denoised_events = []\n",
        "\n",
        "    # Extract patches with enhanced polarity for all events in batches\n",
        "    features = extract_patches_batch(ti, polarity_img, events, patch_size, tau, batch_size)\n",
        "\n",
        "    # Predict in batches\n",
        "    predictions = []\n",
        "    for i in range(0, len(features), batch_size):\n",
        "        batch_features = features[i:i+batch_size]\n",
        "        batch_predictions = model.predict(batch_features, verbose=0)\n",
        "        predictions.extend(batch_predictions)\n",
        "\n",
        "    predictions = np.array(predictions).flatten()\n",
        "\n",
        "    # Filter events based on predictions\n",
        "    for i, (t, x, y, p) in enumerate(events):\n",
        "        if predictions[i] >= threshold:\n",
        "            denoised_events.append((t, x, y, p))\n",
        "\n",
        "            # Update timestamp image and polarity image\n",
        "            if 0 <= x < width and 0 <= y < height:\n",
        "                ti[y, x] = t\n",
        "                polarity_img[y, x] = 1 if p == 1 else -1\n",
        "\n",
        "    return np.array(denoised_events, dtype=[('t', np.float32), ('x', np.int16), ('y', np.int16), ('p', np.int8)])"
      ],
      "metadata": {
        "id": "EzmAcA3uMK5I"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_denoise_events_to_csv(input_file, output_file, model_path,\n",
        "                               patch_size=7, tau=0.1, threshold=0.5, batch_size=128,\n",
        "                               is_csv=False, csv_cols=[0, 1, 2, 3], max_events=None):\n",
        "    \"\"\"\n",
        "    Denoise events from a file and save results to CSV.\n",
        "\n",
        "    Args:\n",
        "        input_file: Path to input events file (TXT or CSV)\n",
        "        output_file: Path to output CSV file for denoised events\n",
        "        model_path: Path to trained denoiser model (.h5 file)\n",
        "        patch_size: Size of patch for feature extraction\n",
        "        tau: Time correlation window for normalization\n",
        "        threshold: Classification threshold for denoising\n",
        "        batch_size: Batch size for processing\n",
        "        is_csv: Whether input is CSV format (True) or space-delimited text (False)\n",
        "        max_events: Maximum events to process (None for all)\n",
        "    \"\"\"\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.keras.models import load_model\n",
        "    import time\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Step 1: Load model\n",
        "    print(f\"Loading model from {model_path}...\")\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # Step 2: Load events\n",
        "    print(f\"Loading events from {input_file}...\")\n",
        "    if is_csv:\n",
        "        events = load_events_from_csv(input_file, max_events)\n",
        "    else:\n",
        "        events = load_events(input_file, max_events)\n",
        "\n",
        "    # Step 3: Build timestamp image\n",
        "    print(\"Building timestamp image...\")\n",
        "    width, height = 346, 260  # DAVIS346 resolution\n",
        "    ti, polarity_img = build_timestamp_image_parallel(events, width, height)\n",
        "\n",
        "    # Step 4: Denoise events\n",
        "    print(\"Denoising events...\")\n",
        "    denoised_events = denoise_events(events, model, ti, polarity_img,\n",
        "                                    patch_size, tau, threshold, batch_size)\n",
        "\n",
        "    # Step 5: Save to CSV\n",
        "    print(f\"Saving denoised events to {output_file}...\")\n",
        "    save_events_to_csv(denoised_events, output_file)\n",
        "\n",
        "    processing_time = time.time() - start_time\n",
        "    original_count = len(events)\n",
        "    denoised_count = len(denoised_events)\n",
        "    removed_pct = 100 * (1 - denoised_count/original_count)\n",
        "\n",
        "    print(f\"Denoising completed in {processing_time:.2f} seconds\")\n",
        "    print(f\"Original events: {original_count}\")\n",
        "    print(f\"Denoised events: {denoised_count}\")\n",
        "    print(f\"Removed noise: {removed_pct:.2f}%\")\n",
        "\n",
        "    return denoised_events"
      ],
      "metadata": {
        "id": "eTOzYOZbc1ft"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/DVSTraining/custom_dataloader /content/"
      ],
      "metadata": {
        "id": "n96YqO1Z6ryp"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the custom Dataset class\n",
        "from custom_dataloader.dataset import Dataset\n",
        "from custom_dataloader.dataloader import ti_image_generator, default_collate_fn\n",
        "\n",
        "# DVS Event Dataset implementation\n",
        "class DVSEventDataset(Dataset):\n",
        "    def __init__(self, csv_file, t_col, x_col, y_col, p_col, patch_size=7, tau=0.1, dtype='float32'):\n",
        "        \"\"\"\n",
        "        Dataset for DVS events from CSV file.\n",
        "\n",
        "        Args:\n",
        "            csv_file: Path to CSV file\n",
        "            t_col, x_col, y_col, p_col: Column indices for event data\n",
        "            patch_size: Size of patch for feature extraction\n",
        "            tau: Time correlation window\n",
        "            dtype: Data type for tensors\n",
        "        \"\"\"\n",
        "        super(DVSEventDataset, self).__init__(dtype=dtype)\n",
        "        print(f\"Loading CSV data from {csv_file}...\")\n",
        "\n",
        "        # Read CSV file\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "\n",
        "        # Get column names\n",
        "        self.t_col = self.df.columns[t_col]\n",
        "        self.x_col = self.df.columns[x_col]\n",
        "        self.y_col = self.df.columns[y_col]\n",
        "        self.p_col = self.df.columns[p_col]\n",
        "\n",
        "        print(f\"Using columns: t={self.t_col}, x={self.x_col}, y={self.y_col}, p={self.p_col}\")\n",
        "\n",
        "        # Extract events\n",
        "        self.events = np.array(list(zip(\n",
        "            self.df[self.t_col].astype(float),\n",
        "            self.df[self.x_col].astype(int),\n",
        "            self.df[self.y_col].astype(int),\n",
        "            self.df[self.p_col].astype(int)\n",
        "        )), dtype=[('t', np.float64), ('x', np.int32), ('y', np.int32), ('p', np.int32)])\n",
        "\n",
        "        # Create timestamp and polarity images\n",
        "        self.width = 346\n",
        "        self.height = 260\n",
        "        self.patch_size = patch_size\n",
        "        self.tau = tau\n",
        "        self.half_size = patch_size // 2\n",
        "\n",
        "        # Build timestamp and polarity images\n",
        "        self.ti, self.polarity_img = self._build_timestamp_image()\n",
        "\n",
        "        print(f\"✅ Dataset loaded with {len(self.events)} events\")\n",
        "\n",
        "    def _build_timestamp_image(self):\n",
        "        \"\"\"Build timestamp and polarity images from events.\"\"\"\n",
        "        ti = np.zeros((self.height, self.width), dtype=np.float64)\n",
        "        polarity_img = np.zeros((self.height, self.width), dtype=np.float32)\n",
        "\n",
        "        for t, x, y, p in self.events:\n",
        "            if 0 <= x < self.width and 0 <= y < self.height:\n",
        "                ti[y, x] = t\n",
        "                polarity_img[y, x] = 1 if p > 0 else -1\n",
        "\n",
        "        return ti, polarity_img\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the number of events in the dataset.\"\"\"\n",
        "        return len(self.events)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Get a sample from the dataset at the given index.\"\"\"\n",
        "        t, x, y, p = self.events[idx]\n",
        "\n",
        "        # Create feature vector (patch)\n",
        "        features = self._extract_patch(t, x, y, p)\n",
        "\n",
        "        # Return dictionary with x features and y label (0 for all in single dataset)\n",
        "        return {\n",
        "            'x': features,\n",
        "            'y': np.array([0], dtype=self.dtype)  # Default label, will be updated when matching\n",
        "        }\n",
        "\n",
        "    def _extract_patch(self, t, x, y, p):\n",
        "        \"\"\"Extract patch around event.\"\"\"\n",
        "        # Handle boundaries\n",
        "        if x < self.half_size or x >= self.width - self.half_size or y < self.half_size or y >= self.height - self.half_size:\n",
        "            # Create empty patches\n",
        "            time_patch = np.zeros((self.patch_size, self.patch_size), dtype=np.float32)\n",
        "            pol_patch = np.zeros((self.patch_size, self.patch_size), dtype=np.float32)\n",
        "\n",
        "            # Calculate patch boundaries and offsets\n",
        "            x_min = max(0, x - self.half_size)\n",
        "            x_max = min(self.width, x + self.half_size + 1)\n",
        "            y_min = max(0, y - self.half_size)\n",
        "            y_max = min(self.height, y + self.half_size + 1)\n",
        "\n",
        "            x_offset = self.half_size - (x - x_min)\n",
        "            y_offset = self.half_size - (y - y_min)\n",
        "\n",
        "            # Copy data into patches\n",
        "            patch_width = x_max - x_min\n",
        "            patch_height = y_max - y_min\n",
        "\n",
        "            time_patch[y_offset:y_offset+patch_height, x_offset:x_offset+patch_width] = self.ti[y_min:y_max, x_min:x_max]\n",
        "            pol_patch[y_offset:y_offset+patch_height, x_offset:x_offset+patch_width] = self.polarity_img[y_min:y_max, x_min:x_max]\n",
        "        else:\n",
        "            # Extract patches directly\n",
        "            time_patch = self.ti[y-self.half_size:y+self.half_size+1, x-self.half_size:x+self.half_size+1].copy()\n",
        "            pol_patch = self.polarity_img[y-self.half_size:y+self.half_size+1, x-self.half_size:x+self.half_size+1].copy()\n",
        "\n",
        "        # Normalize the timestamp patch\n",
        "        time_diff = t - time_patch\n",
        "        time_patch_norm = np.clip((self.tau - np.abs(time_diff)) / self.tau, 0, 1)\n",
        "\n",
        "        # Set the central pixel's polarity\n",
        "        center = self.patch_size // 2\n",
        "        pol_patch[center, center] = 1 if p > 0 else -1\n",
        "\n",
        "        # Create a separate polarity channel for enhanced encoding (like paper)\n",
        "        pol_channel2 = np.zeros_like(pol_patch)\n",
        "        pol_channel2[center, center] = 1 if p > 0 else -1\n",
        "\n",
        "        # Flatten and combine all channels - use 3 channels as in \"polarity=2\" model\n",
        "        features = np.hstack((\n",
        "            time_patch_norm.flatten(),\n",
        "            pol_patch.flatten(),\n",
        "            pol_channel2.flatten()\n",
        "        )).astype(self.dtype)\n",
        "\n",
        "        return features"
      ],
      "metadata": {
        "id": "QaVFKUze6A1e"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MatchedDVSDataset(Dataset):\n",
        "    def __init__(self, noisy_dataset, clean_dataset, tau=1.0, spatial_threshold=2, dtype='float32'):\n",
        "        \"\"\"\n",
        "        Dataset wrapper that matches noisy events with clean events to create labeled data.\n",
        "\n",
        "        Args:\n",
        "            noisy_dataset: DVSEventDataset with noisy events\n",
        "            clean_dataset: DVSEventDataset with clean events\n",
        "            tau: Time correlation window (in seconds)\n",
        "            spatial_threshold: Maximum spatial distance to consider a match\n",
        "            dtype: Data type for tensors\n",
        "        \"\"\"\n",
        "        super(MatchedDVSDataset, self).__init__(dtype=dtype)\n",
        "        self.noisy_dataset = noisy_dataset\n",
        "        self.clean_dataset = clean_dataset\n",
        "        self.tau = tau\n",
        "        self.spatial_threshold = spatial_threshold\n",
        "\n",
        "        # Create labels by matching events\n",
        "        self.labels = self._match_events()\n",
        "        print(f\"Found {np.sum(self.labels)} signal events and {len(self.labels) - np.sum(self.labels)} noise events\")\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the number of events in the dataset.\"\"\"\n",
        "        return len(self.noisy_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Get a sample from the dataset with correct label.\"\"\"\n",
        "        sample = self.noisy_dataset[idx]\n",
        "        sample['y'] = np.array([self.labels[idx]], dtype=self.dtype)\n",
        "        return sample\n",
        "\n",
        "    def _match_events(self):\n",
        "        \"\"\"Match noisy events to clean events using spatiotemporal correlation.\"\"\"\n",
        "        # Build a spatial index for clean events\n",
        "        clean_event_dict = defaultdict(list)\n",
        "        for i in range(len(self.clean_dataset)):\n",
        "            t, x, y, p = self.clean_dataset.events[i]\n",
        "            # Store events by their spatial location with some tolerance\n",
        "            for dx in range(-self.spatial_threshold, self.spatial_threshold + 1):\n",
        "                for dy in range(-self.spatial_threshold, self.spatial_threshold + 1):\n",
        "                    clean_event_dict[(x+dx, y+dy)].append((t, p, i))\n",
        "\n",
        "        # Create labels array\n",
        "        labels = np.zeros(len(self.noisy_dataset), dtype=np.int8)\n",
        "\n",
        "        # Match each noisy event to clean events\n",
        "        for i in range(len(self.noisy_dataset)):\n",
        "            t_noisy, x_noisy, y_noisy, p_noisy = self.noisy_dataset.events[i]\n",
        "\n",
        "            # Check if there are any clean events at this location\n",
        "            for t_clean, p_clean, _ in clean_event_dict.get((x_noisy, y_noisy), []):\n",
        "                # Check temporal correlation with larger window\n",
        "                if abs(t_noisy - t_clean) < self.tau:\n",
        "                    # Check polarity match with less strict condition\n",
        "                    # Consider it a match if either both positive or both negative\n",
        "                    if (p_noisy > 0 and p_clean > 0) or (p_noisy <= 0 and p_clean <= 0):\n",
        "                        labels[i] = 1\n",
        "                        break\n",
        "\n",
        "        return labels"
      ],
      "metadata": {
        "id": "3pR8M5op6oRf"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_datasets_and_train():\n",
        "    \"\"\"\n",
        "    Create datasets and train the model using the custom dataloader.\n",
        "    \"\"\"\n",
        "    # Define CSV column mappings based on visual inspection of data\n",
        "    # These are indices, so they're 0-based\n",
        "    noisy_p_col = 0  # Column \"-1\" has values 1, 1, -1, etc. - likely polarity\n",
        "    noisy_x_col = 1  # Column \"60\" has values in camera coordinate range\n",
        "    noisy_y_col = 2  # Column \"131\" has values in camera coordinate range\n",
        "    noisy_t_col = 3  # Column \"1610903445\" has large values - likely timestamps\n",
        "\n",
        "    clean_x_col = 0  # Column \"265\" has values in camera coordinate range\n",
        "    clean_y_col = 1  # Column \"226\" has values in camera coordinate range\n",
        "    clean_t_col = 2  # Column \"1608383420\" has large values - likely timestamps\n",
        "    clean_p_col = 3  # Column \"0\" has values 1, 1, 1, etc. - likely polarity\n",
        "\n",
        "    # Create datasets\n",
        "    print(\"Creating datasets...\")\n",
        "    noisy_dataset = DVSEventDataset(\n",
        "        noisy_file,\n",
        "        t_col=noisy_t_col,\n",
        "        x_col=noisy_x_col,\n",
        "        y_col=noisy_y_col,\n",
        "        p_col=noisy_p_col,\n",
        "        patch_size=7,\n",
        "        tau=0.1\n",
        "    )\n",
        "\n",
        "    clean_dataset = DVSEventDataset(\n",
        "        clean_file,\n",
        "        t_col=clean_t_col,\n",
        "        x_col=clean_x_col,\n",
        "        y_col=clean_y_col,\n",
        "        p_col=clean_p_col,\n",
        "        patch_size=7,\n",
        "        tau=0.1\n",
        "    )\n",
        "\n",
        "    # Create matched dataset with more relaxed parameters\n",
        "    matched_dataset = MatchedDVSDataset(\n",
        "        noisy_dataset,\n",
        "        clean_dataset,\n",
        "        tau=5.0,  # Much larger window\n",
        "        spatial_threshold=3  # Larger spatial threshold\n",
        "    )\n",
        "\n",
        "    # Split into train and validation sets\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    indices = np.arange(len(matched_dataset))\n",
        "    train_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_dataset = SubsetDataset(matched_dataset, train_indices)\n",
        "    val_dataset = SubsetDataset(matched_dataset, val_indices)\n",
        "\n",
        "    print(f\"Training set: {len(train_dataset)} samples, Validation set: {len(val_dataset)} samples\")\n",
        "\n",
        "    # Create data generators\n",
        "    train_generator = ti_image_generator(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=128,\n",
        "        shuffle=True,\n",
        "        num_workers=4\n",
        "    )\n",
        "\n",
        "    val_generator = ti_image_generator(\n",
        "        dataset=val_dataset,\n",
        "        batch_size=128,\n",
        "        shuffle=False,\n",
        "        num_workers=4\n",
        "    )\n",
        "\n",
        "    # Build and train model\n",
        "    # Get input dimension from first sample\n",
        "    input_dim = train_dataset[0]['x'].shape[0]\n",
        "\n",
        "    model = build_mlpf_model(input_dim, hidden_units=20)\n",
        "\n",
        "    # Compile model\n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='mean_squared_error',\n",
        "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "\n",
        "    # Callbacks\n",
        "    checkpoint_path = os.path.join(output_dir, \"mlpf_model_best.h5\")\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        checkpoint_path,\n",
        "        monitor='val_auc',\n",
        "        verbose=1,\n",
        "        save_best_only=True,\n",
        "        mode='max'\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=val_generator,\n",
        "        epochs=30,\n",
        "        callbacks=[checkpoint],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Load best model\n",
        "    best_model = load_model(checkpoint_path)\n",
        "\n",
        "    return best_model, history, matched_dataset"
      ],
      "metadata": {
        "id": "PIysvxEF7YeF"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SubsetDataset(Dataset):\n",
        "    \"\"\"Dataset to take a subset specified by indices.\"\"\"\n",
        "\n",
        "    def __init__(self, dataset, indices, dtype='float32'):\n",
        "        super(SubsetDataset, self).__init__(dtype=dtype)\n",
        "        self.dataset = dataset\n",
        "        self.indices = indices\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.dataset[self.indices[idx]]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)"
      ],
      "metadata": {
        "id": "KheZuDCu7w_T"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Get file format from earlier input\n",
        "    is_csv = (file_format == \"csv\")\n",
        "\n",
        "    # CSV parameters if using CSV files\n",
        "    csv_cols = [0, 1, 2, 3]  # Use first 4 columns for t, x, y, p\n",
        "\n",
        "    # Other parameters\n",
        "    patch_size = 7\n",
        "    tau = 0.1\n",
        "    hidden_units = 20\n",
        "    batch_size = 128\n",
        "    epochs = 5\n",
        "    convert_to_pb = True\n",
        "    save_denoised = True\n",
        "    output_csv = 'denoised_events.csv'\n",
        "\n",
        "    # Run the pipeline to train a model\n",
        "    model, history, roc_auc = run_denoising_pipeline(\n",
        "        noisy_file,\n",
        "        clean_file,\n",
        "        patch_size,\n",
        "        tau,\n",
        "        hidden_units,\n",
        "        batch_size,\n",
        "        epochs,\n",
        "        convert_to_pb,\n",
        "        input_is_csv=is_csv,\n",
        "        csv_cols=csv_cols,\n",
        "        save_denoised=save_denoised,\n",
        "        output_csv=output_csv\n",
        "    )\n",
        "    print(f\"Training completed. Model AUC: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OpKLCT7nMOBg",
        "outputId": "993dbd08-e94b-4bd5-d51a-6382e9052514"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Preview of data from /content/drive/MyDrive/DVSTraining/mixedhotellightTI25.csv:\n",
            "   -1   60  131  1610903445  1  2090596  5096365  2089490  2120375  2079095  \\\n",
            "0   1  181  158  1610903470  1  2120900  5579979  3438179  3001284  5335559   \n",
            "1   1  172  159  1610903475  1  2114237  5246538  5104601  3884158        0   \n",
            "2  -1  189  154  1610903489  1  2081398  5158468        0  2138209  5492236   \n",
            "3   1  165  159  1610903505  1        0  4325362        0  3118796  5078815   \n",
            "4   1  185  132  1610903509  1        0  2874090  4775733  2123682  5099596   \n",
            "\n",
            "   ...  0.678  0.679  0.680  0.681  0.682  0.683  0.684  0.685  0.686  \\\n",
            "0  ...      0      0      0      0      0      0      0      0      0   \n",
            "1  ...      0      0      0      0      0      0      0      0      0   \n",
            "2  ...      0      0      0      0      0      0      0      0      0   \n",
            "3  ...      0      0      0      0      0      0      0      0      0   \n",
            "4  ...      0      0      0      0      0      0      0      0      0   \n",
            "\n",
            "   1610903445.1  \n",
            "0    1610903445  \n",
            "1    1610903445  \n",
            "2    1610903445  \n",
            "3    1610903445  \n",
            "4    1610903445  \n",
            "\n",
            "[5 rows x 1256 columns]\n",
            "Using columns -1, 60, 131, 1610903445 for t, x, y, p\n",
            "Value ranges:\n",
            "  t: -1 to 1\n",
            "  x: 0 to 345\n",
            "  y: 0 to 259\n",
            "  p: 1607383422 to 1611214820\n",
            "✅ Loaded 79673 events from CSV with data types: t=<class 'numpy.float64'>, x=<class 'numpy.int16'>, y=<class 'numpy.int16'>, p=<class 'numpy.int32'>\n",
            "Preview of data from /content/drive/MyDrive/DVSTraining/amixedhotellightTI25.csv:\n",
            "   265  226  1608383420  0      0.1  2795048  4632868  4529021  4522710  \\\n",
            "0  283  166  1608383425  1  4618167  4615269  4590981  4578587  4563194   \n",
            "1  108  168  1608383425  1  4657548        0  4657799  4620166  4600876   \n",
            "2  263  153  1608383427  1  4648053  4640656  4652750  4638158  4653350   \n",
            "3  114  154  1608383481  1  4590679  4558433  4550100  2868324        0   \n",
            "4  101  134  1608383485  1  4617268  4590781  4566792  2871912  4629264   \n",
            "\n",
            "   4639112  ...    0.244  4541095    0.245  4538226  4650382    0.246  \\\n",
            "0  4647353  ...  2807543  2810416  4654950  2903543  4627263  4645844   \n",
            "1  4647307  ...  4634160  4598177  4628892  4576188        0  4624064   \n",
            "2  4628290  ...  4592280  4577587  4545203  4526912        0  4566681   \n",
            "3        0  ...        0  4654817  2894701  2915390  4585883  4630162   \n",
            "4  4576499  ...  4579086  4546002  4516716  4649531  2905395  2873311   \n",
            "\n",
            "   4533849  4645822    0.247  1608383425  \n",
            "0  4637223  4583654  2904596  1608383425  \n",
            "1  4584384  4560695  4560548  1608383425  \n",
            "2  4580785  4649788  4520915  1608383425  \n",
            "3  4626905  4576987  4535670  1608383425  \n",
            "4  4651639        0  4650796  1608383425  \n",
            "\n",
            "[5 rows x 630 columns]\n",
            "Using columns 265, 226, 1608383420, 0 for t, x, y, p\n",
            "Value ranges:\n",
            "  t: 0 to 345\n",
            "  x: 0 to 259\n",
            "  y: 1608383425 to 1608883405\n",
            "  p: 0 to 1\n",
            "✅ Loaded 35624 events from CSV with data types: t=<class 'numpy.float64'>, x=<class 'numpy.int16'>, y=<class 'numpy.int32'>, p=<class 'numpy.int8'>\n",
            "Data loading completed in 11.24 seconds\n",
            "Building timestamp images...\n",
            "Timestamp image building completed in 0.99 seconds\n",
            "Matching events for training labels...\n",
            "Event matching completed in 0.62 seconds\n",
            "Found 0 signal events and 79673 noise events\n",
            "Extracting patches...\n",
            "Patch extraction completed in 2.80 seconds\n",
            "Training set: 63738 samples, Validation set: 15935 samples\n",
            "Training model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"MLPF\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MLPF\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m147\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ fc1 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │         \u001b[38;5;34m2,960\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">147</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ fc1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,960</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,981\u001b[0m (11.64 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,981</span> (11.64 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,981\u001b[0m (11.64 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,981</span> (11.64 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9751 - auc: 0.0000e+00 - loss: 0.1517\n",
            "Epoch 1: val_auc improved from -inf to 0.00000, saving model to mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9751 - auc: 0.0000e+00 - loss: 0.1516 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0579\n",
            "Epoch 2/5\n",
            "\u001b[1m485/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 0.0506\n",
            "Epoch 2: val_auc did not improve from 0.00000\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 0.0504 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0239\n",
            "Epoch 3/5\n",
            "\u001b[1m486/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 0.0236\n",
            "Epoch 3: val_auc did not improve from 0.00000\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 0.0235 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0118\n",
            "Epoch 4/5\n",
            "\u001b[1m488/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 0.0129\n",
            "Epoch 4: val_auc did not improve from 0.00000\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 0.0128 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0064\n",
            "Epoch 5/5\n",
            "\u001b[1m478/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 0.0076\n",
            "Epoch 5: val_auc did not improve from 0.00000\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 0.0076 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0037\n",
            "Training completed in 10.89 seconds\n",
            "Evaluating model...\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 0.0037\n",
            "Validation loss: 0.0037\n",
            "Validation compile_metrics: 1.0000\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:1188: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 4, got 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-b0a926739c7a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Run the pipeline to train a model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     model, history, roc_auc = run_denoising_pipeline(\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mnoisy_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mclean_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-17d487be246d>\u001b[0m in \u001b[0;36mrun_denoising_pipeline\u001b[0;34m(noisy_file, clean_file, patch_size, tau, hidden_units, batch_size, epochs, convert_to_pb, input_is_csv, csv_cols, save_denoised, output_csv)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# Calculate manual ROC and AUC using the paper's methodology\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mroc_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_manual_roc_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Standard AUC: {roc_auc_standard:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-0fb5bde302d1>\u001b[0m in \u001b[0;36mcalculate_manual_roc_auc\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 10%, 30%, 50%, 70%, 90%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0my_pred_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mfpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create output directory on Google Drive\n",
        "output_dir = os.path.join(base_path, \"results\")\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Train model with custom dataset approach\n",
        "model, history, matched_dataset = create_datasets_and_train()\n",
        "\n",
        "# Save model to Google Drive\n",
        "model_path = os.path.join(output_dir, \"mlpf_model_final.h5\")\n",
        "model.save(model_path)\n",
        "print(f\"Model saved to Google Drive: {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVxPjW7K8eWy",
        "outputId": "90b5e3c0-febf-41f4-bd03-342a3acc9b0f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating datasets...\n",
            "Loading CSV data from /content/drive/MyDrive/DVSTraining/mixedhotellightTI25.csv...\n",
            "Using columns: t=1610903445, x=60, y=131, p=-1\n",
            "✅ Dataset loaded with 79673 events\n",
            "Loading CSV data from /content/drive/MyDrive/DVSTraining/amixedhotellightTI25.csv...\n",
            "Using columns: t=1608383420, x=265, y=226, p=0\n",
            "✅ Dataset loaded with 35624 events\n",
            "Found 9610 signal events and 70063 noise events\n",
            "Training set: 63738 samples, Validation set: 15935 samples\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m494/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7194 - auc: 0.4067 - loss: 0.2054\n",
            "Epoch 1: val_auc improved from -inf to 0.39816, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.7203 - auc: 0.4069 - loss: 0.2051 - val_accuracy: 0.8794 - val_auc: 0.3982 - val_loss: 0.1283\n",
            "Epoch 2/30\n",
            "\u001b[1m495/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8809 - auc: 0.4859 - loss: 0.1258\n",
            "Epoch 2: val_auc improved from 0.39816 to 0.48818, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8809 - auc: 0.4859 - loss: 0.1257 - val_accuracy: 0.8794 - val_auc: 0.4882 - val_loss: 0.1104\n",
            "Epoch 3/30\n",
            "\u001b[1m495/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8790 - auc: 0.5314 - loss: 0.1143\n",
            "Epoch 3: val_auc improved from 0.48818 to 0.75722, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8790 - auc: 0.5315 - loss: 0.1143 - val_accuracy: 0.8794 - val_auc: 0.7572 - val_loss: 0.1044\n",
            "Epoch 4/30\n",
            "\u001b[1m494/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8764 - auc: 0.6087 - loss: 0.1099\n",
            "Epoch 4: val_auc improved from 0.75722 to 0.81966, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8764 - auc: 0.6088 - loss: 0.1099 - val_accuracy: 0.8794 - val_auc: 0.8197 - val_loss: 0.0998\n",
            "Epoch 5/30\n",
            "\u001b[1m494/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8815 - auc: 0.6964 - loss: 0.1016\n",
            "Epoch 5: val_auc improved from 0.81966 to 0.83902, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.8815 - auc: 0.6965 - loss: 0.1016 - val_accuracy: 0.8794 - val_auc: 0.8390 - val_loss: 0.0957\n",
            "Epoch 6/30\n",
            "\u001b[1m496/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8801 - auc: 0.7528 - loss: 0.0983\n",
            "Epoch 6: val_auc improved from 0.83902 to 0.84288, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8801 - auc: 0.7529 - loss: 0.0983 - val_accuracy: 0.8794 - val_auc: 0.8429 - val_loss: 0.0929\n",
            "Epoch 7/30\n",
            "\u001b[1m495/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8781 - auc: 0.7923 - loss: 0.0963\n",
            "Epoch 7: val_auc improved from 0.84288 to 0.84409, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8781 - auc: 0.7923 - loss: 0.0963 - val_accuracy: 0.8794 - val_auc: 0.8441 - val_loss: 0.0912\n",
            "Epoch 8/30\n",
            "\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8763 - auc: 0.8017 - loss: 0.0953\n",
            "Epoch 8: val_auc improved from 0.84409 to 0.84499, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8763 - auc: 0.8017 - loss: 0.0953 - val_accuracy: 0.8794 - val_auc: 0.8450 - val_loss: 0.0902\n",
            "Epoch 9/30\n",
            "\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8799 - auc: 0.8056 - loss: 0.0922\n",
            "Epoch 9: val_auc improved from 0.84499 to 0.84826, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8799 - auc: 0.8056 - loss: 0.0922 - val_accuracy: 0.8794 - val_auc: 0.8483 - val_loss: 0.0892\n",
            "Epoch 10/30\n",
            "\u001b[1m495/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8784 - auc: 0.8087 - loss: 0.0928\n",
            "Epoch 10: val_auc improved from 0.84826 to 0.84957, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8784 - auc: 0.8087 - loss: 0.0928 - val_accuracy: 0.8794 - val_auc: 0.8496 - val_loss: 0.0887\n",
            "Epoch 11/30\n",
            "\u001b[1m495/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8822 - auc: 0.8098 - loss: 0.0902\n",
            "Epoch 11: val_auc improved from 0.84957 to 0.85149, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8822 - auc: 0.8098 - loss: 0.0902 - val_accuracy: 0.8794 - val_auc: 0.8515 - val_loss: 0.0878\n",
            "Epoch 12/30\n",
            "\u001b[1m496/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8802 - auc: 0.8122 - loss: 0.0914\n",
            "Epoch 12: val_auc improved from 0.85149 to 0.85294, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8802 - auc: 0.8122 - loss: 0.0914 - val_accuracy: 0.8802 - val_auc: 0.8529 - val_loss: 0.0874\n",
            "Epoch 13/30\n",
            "\u001b[1m495/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8843 - auc: 0.8145 - loss: 0.0890\n",
            "Epoch 13: val_auc improved from 0.85294 to 0.85362, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8843 - auc: 0.8146 - loss: 0.0890 - val_accuracy: 0.8808 - val_auc: 0.8536 - val_loss: 0.0871\n",
            "Epoch 14/30\n",
            "\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8821 - auc: 0.8223 - loss: 0.0891\n",
            "Epoch 14: val_auc improved from 0.85362 to 0.85552, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8821 - auc: 0.8223 - loss: 0.0891 - val_accuracy: 0.8811 - val_auc: 0.8555 - val_loss: 0.0865\n",
            "Epoch 15/30\n",
            "\u001b[1m494/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8837 - auc: 0.8168 - loss: 0.0894\n",
            "Epoch 15: val_auc improved from 0.85552 to 0.85648, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8837 - auc: 0.8168 - loss: 0.0894 - val_accuracy: 0.8820 - val_auc: 0.8565 - val_loss: 0.0862\n",
            "Epoch 16/30\n",
            "\u001b[1m495/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8840 - auc: 0.8157 - loss: 0.0890\n",
            "Epoch 16: val_auc did not improve from 0.85648\n",
            "\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8840 - auc: 0.8157 - loss: 0.0890 - val_accuracy: 0.8831 - val_auc: 0.8556 - val_loss: 0.0861\n",
            "Epoch 17/30\n",
            "\u001b[1m495/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8856 - auc: 0.8209 - loss: 0.0876\n",
            "Epoch 17: val_auc improved from 0.85648 to 0.85648, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8856 - auc: 0.8209 - loss: 0.0876 - val_accuracy: 0.8830 - val_auc: 0.8565 - val_loss: 0.0859\n",
            "Epoch 18/30\n",
            "\u001b[1m496/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8822 - auc: 0.8221 - loss: 0.0897\n",
            "Epoch 18: val_auc improved from 0.85648 to 0.85657, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8822 - auc: 0.8221 - loss: 0.0896 - val_accuracy: 0.8831 - val_auc: 0.8566 - val_loss: 0.0858\n",
            "Epoch 19/30\n",
            "\u001b[1m496/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8839 - auc: 0.8262 - loss: 0.0878\n",
            "Epoch 19: val_auc improved from 0.85657 to 0.85685, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8839 - auc: 0.8261 - loss: 0.0878 - val_accuracy: 0.8841 - val_auc: 0.8568 - val_loss: 0.0852\n",
            "Epoch 20/30\n",
            "\u001b[1m492/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8858 - auc: 0.8268 - loss: 0.0868\n",
            "Epoch 20: val_auc improved from 0.85685 to 0.85686, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8858 - auc: 0.8268 - loss: 0.0868 - val_accuracy: 0.8843 - val_auc: 0.8569 - val_loss: 0.0849\n",
            "Epoch 21/30\n",
            "\u001b[1m496/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8838 - auc: 0.8224 - loss: 0.0882\n",
            "Epoch 21: val_auc did not improve from 0.85686\n",
            "\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8838 - auc: 0.8224 - loss: 0.0882 - val_accuracy: 0.8846 - val_auc: 0.8568 - val_loss: 0.0848\n",
            "Epoch 22/30\n",
            "\u001b[1m495/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8856 - auc: 0.8283 - loss: 0.0867\n",
            "Epoch 22: val_auc improved from 0.85686 to 0.85844, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8856 - auc: 0.8283 - loss: 0.0867 - val_accuracy: 0.8850 - val_auc: 0.8584 - val_loss: 0.0844\n",
            "Epoch 23/30\n",
            "\u001b[1m496/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8872 - auc: 0.8279 - loss: 0.0857\n",
            "Epoch 23: val_auc improved from 0.85844 to 0.85923, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8872 - auc: 0.8279 - loss: 0.0857 - val_accuracy: 0.8851 - val_auc: 0.8592 - val_loss: 0.0842\n",
            "Epoch 24/30\n",
            "\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8870 - auc: 0.8305 - loss: 0.0859\n",
            "Epoch 24: val_auc did not improve from 0.85923\n",
            "\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8870 - auc: 0.8305 - loss: 0.0859 - val_accuracy: 0.8856 - val_auc: 0.8583 - val_loss: 0.0841\n",
            "Epoch 25/30\n",
            "\u001b[1m493/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8855 - auc: 0.8306 - loss: 0.0866\n",
            "Epoch 25: val_auc did not improve from 0.85923\n",
            "\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8855 - auc: 0.8306 - loss: 0.0866 - val_accuracy: 0.8857 - val_auc: 0.8586 - val_loss: 0.0843\n",
            "Epoch 26/30\n",
            "\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8851 - auc: 0.8333 - loss: 0.0865\n",
            "Epoch 26: val_auc improved from 0.85923 to 0.86033, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8851 - auc: 0.8333 - loss: 0.0865 - val_accuracy: 0.8857 - val_auc: 0.8603 - val_loss: 0.0838\n",
            "Epoch 27/30\n",
            "\u001b[1m495/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8843 - auc: 0.8311 - loss: 0.0870\n",
            "Epoch 27: val_auc improved from 0.86033 to 0.86183, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8844 - auc: 0.8311 - loss: 0.0870 - val_accuracy: 0.8861 - val_auc: 0.8618 - val_loss: 0.0834\n",
            "Epoch 28/30\n",
            "\u001b[1m495/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8851 - auc: 0.8305 - loss: 0.0870\n",
            "Epoch 28: val_auc improved from 0.86183 to 0.86251, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.8851 - auc: 0.8306 - loss: 0.0870 - val_accuracy: 0.8861 - val_auc: 0.8625 - val_loss: 0.0834\n",
            "Epoch 29/30\n",
            "\u001b[1m489/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8849 - auc: 0.8392 - loss: 0.0860\n",
            "Epoch 29: val_auc improved from 0.86251 to 0.86314, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8849 - auc: 0.8392 - loss: 0.0860 - val_accuracy: 0.8865 - val_auc: 0.8631 - val_loss: 0.0830\n",
            "Epoch 30/30\n",
            "\u001b[1m494/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8869 - auc: 0.8372 - loss: 0.0850\n",
            "Epoch 30: val_auc improved from 0.86314 to 0.86439, saving model to /content/drive/MyDrive/DVSTraining/results/mlpf_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8869 - auc: 0.8372 - loss: 0.0850 - val_accuracy: 0.8869 - val_auc: 0.8644 - val_loss: 0.0828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to Google Drive: /content/drive/MyDrive/DVSTraining/results/mlpf_model_final.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After training is complete, calculate AUC and plot ROC curve\n",
        "def evaluate_model_auc(model, matched_dataset, batch_size=128):\n",
        "    \"\"\"\n",
        "    Evaluate model AUC and plot ROC curve.\n",
        "    \"\"\"\n",
        "    from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Create evaluation dataset\n",
        "    # Use all data for simplicity, or you could use just validation data\n",
        "    eval_generator = ti_image_generator(\n",
        "        dataset=matched_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=4\n",
        "    )\n",
        "\n",
        "    # Get predictions and true labels\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    for i in range(len(eval_generator)):\n",
        "        X_batch, y_batch = eval_generator[i]\n",
        "        predictions = model.predict(X_batch, verbose=0)\n",
        "        all_predictions.extend(predictions.flatten())\n",
        "        all_labels.extend(y_batch.flatten())\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # Calculate AUC\n",
        "    auc_score = roc_auc_score(all_labels, all_predictions)\n",
        "    print(f\"AUC Score: {auc_score:.4f}\")\n",
        "\n",
        "    # Calculate ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(all_labels, all_predictions)\n",
        "\n",
        "    # Calculate manual ROC curve using paper method\n",
        "    tps = []\n",
        "    fps = []\n",
        "    for threshold in [0.1, 0.3, 0.5, 0.7, 0.9, 0.99]:\n",
        "        y_pred_binary = (all_predictions > threshold).astype(int)\n",
        "        cm = confusion_matrix(all_labels, y_pred_binary)\n",
        "\n",
        "        if cm.shape == (2, 2):  # Perfect shape\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "        else:  # Handle edge cases\n",
        "            tn = cm[0, 0] if cm.shape[0] > 0 and cm.shape[1] > 0 else 0\n",
        "            fp = cm[0, 1] if cm.shape[0] > 0 and cm.shape[1] > 1 else 0\n",
        "            fn = cm[1, 0] if cm.shape[0] > 1 and cm.shape[1] > 0 else 0\n",
        "            tp = cm[1, 1] if cm.shape[0] > 1 and cm.shape[1] > 1 else 0\n",
        "\n",
        "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "        tps.append(tpr)\n",
        "        fps.append(fpr)\n",
        "\n",
        "    # Add boundary points\n",
        "    manual_fps = [0] + fps + [1]\n",
        "    manual_tps = [0] + tps + [1]\n",
        "\n",
        "    # Sort by FPR\n",
        "    sorted_pairs = sorted(zip(manual_fps, manual_tps))\n",
        "    manual_fps = [x for x, y in sorted_pairs]\n",
        "    manual_tps = [y for x, y in sorted_pairs]\n",
        "\n",
        "    # Calculate manual AUC\n",
        "    manual_auc = auc(manual_fps, manual_tps)\n",
        "    print(f\"Manual AUC Score: {manual_auc:.4f}\")\n",
        "\n",
        "    # Plot ROC curve\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'Standard ROC (AUC = {auc_score:.4f})')\n",
        "    plt.plot(manual_fps, manual_tps, color='red', lw=2, label=f'Paper Method ROC (AUC = {manual_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Save the plot\n",
        "    roc_path = os.path.join(output_dir, \"roc_curve.pdf\")\n",
        "    plt.savefig(roc_path)\n",
        "    plt.show()\n",
        "\n",
        "    return auc_score, manual_auc\n",
        "\n",
        "# Don't forget to import the confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Evaluate the trained model\n",
        "print(\"Evaluating model and calculating AUC...\")\n",
        "auc_score, manual_auc = evaluate_model_auc(model, matched_dataset)\n",
        "\n",
        "# Save AUC scores\n",
        "with open(os.path.join(output_dir, \"auc_scores.txt\"), \"w\") as f:\n",
        "    f.write(f\"Standard AUC: {auc_score:.4f}\\n\")\n",
        "    f.write(f\"Manual AUC: {manual_auc:.4f}\\n\")\n",
        "\n",
        "print(f\"Evaluation complete. Results saved to {output_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 789
        },
        "id": "g_vRvzV-_tSe",
        "outputId": "cb241060-b04e-4521-d588-07e91bce100e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model and calculating AUC...\n",
            "AUC Score: 0.8741\n",
            "Manual AUC Score: 0.8315\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation complete. Results saved to /content/drive/MyDrive/DVSTraining/results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save h52pb.py to your working directory\n",
        "with open('h52pb.py', 'w') as f:\n",
        "    f.write('''from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import os.path as osp\n",
        "from keras import backend as K\n",
        "\n",
        "import sys\n",
        "input_path = ''\n",
        "weight_file = sys.argv[1]\n",
        "\n",
        "output_graph_name = weight_file[:-3] + '.pb'\n",
        "\n",
        "def h5_to_pb(h5_model,output_dir,model_name,out_prefix = \"output_\",log_tensorboard = True):\n",
        "    if osp.exists(output_dir) == False:\n",
        "        os.mkdir(output_dir)\n",
        "    out_nodes = []\n",
        "    for i in range(len(h5_model.outputs)):\n",
        "        out_nodes.append(out_prefix + str(i + 1))\n",
        "        tf.identity(h5_model.output[i],out_prefix + str(i + 1))\n",
        "    sess = K.get_session()\n",
        "    from tensorflow.python.framework import graph_util,graph_io\n",
        "    init_graph = sess.graph.as_graph_def()\n",
        "    main_graph = graph_util.convert_variables_to_constants(sess,init_graph,out_nodes)\n",
        "    graph_io.write_graph(main_graph,output_dir,name = model_name,as_text = False)\n",
        "    if log_tensorboard:\n",
        "        from tensorflow.python.tools import import_pb_to_tensorboard\n",
        "        import_pb_to_tensorboard.import_to_tensorboard(osp.join(output_dir,model_name),output_dir)\n",
        "\n",
        "output_dir = osp.join(os.getcwd(),\"trans_model\")\n",
        "\n",
        "h5_model = load_model(weight_file)\n",
        "h5_to_pb(h5_model,output_dir = output_dir,model_name = output_graph_name)\n",
        "print('model saved')''')\n",
        "\n",
        "# Run the script with your model path\n",
        "!python h52pb.py /content/drive/MyDrive/DVSTraining/results/mlpf_model_final.h5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9OPsSmVAT4j",
        "outputId": "cf03ca18-88ed-4785-a55b-f61a195bb896"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-14 04:34:44.274825: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747197284.295683  168091 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747197284.302305  168091 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-14 04:34:47.978135: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1747197287.978285  168091 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16664 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/h52pb.py\", line 32, in <module>\n",
            "    h5_to_pb(h5_model,output_dir = output_dir,model_name = output_graph_name)\n",
            "  File \"/content/h52pb.py\", line 19, in h5_to_pb\n",
            "    tf.identity(h5_model.output[i],out_prefix + str(i + 1))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\", line 88, in wrapper\n",
            "    return op(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/keras_tensor.py\", line 138, in __tf_tensor__\n",
            "    raise ValueError(\n",
            "ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n",
            "\n",
            "```\n",
            "x = Input(...)\n",
            "...\n",
            "tf_fn(x)  # Invalid.\n",
            "```\n",
            "\n",
            "What you should do instead is wrap `tf_fn` in a layer:\n",
            "\n",
            "```\n",
            "class MyLayer(Layer):\n",
            "    def call(self, x):\n",
            "        return tf_fn(x)\n",
            "\n",
            "x = MyLayer()(x)\n",
            "```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python h52pb.py /content/drive/MyDrive/DVSTraining/results/mlpf_model_final.h5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2wf6yfdAgzb",
        "outputId": "5fb4611e-4de3-40fb-e2fc-b51bc37c49ff"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-14 04:44:54.121843: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747197894.141534  170820 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747197894.147578  170820 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-14 04:44:58.043719: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1747197898.043865  170820 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16664 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "I0000 00:00:1747197898.991588  170820 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1747197898.991713  170820 single_machine.cc:361] Starting new session\n",
            "I0000 00:00:1747197898.992363  170820 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16664 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n",
            "Model saved as /content/drive/MyDrive/DVSTraining/results/mlpf_model_final.pb\n",
            "Model converted successfully to: /content/drive/MyDrive/DVSTraining/results/mlpf_model_final.pb\n"
          ]
        }
      ]
    }
  ]
}